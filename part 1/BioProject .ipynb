{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "990a9d49",
   "metadata": {},
   "source": [
    "# A project in bioinformatics\n",
    "\n",
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0cd04e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "import os\n",
    "WORKINNG_DIR = os.getcwd()\n",
    "\n",
    "WORDS_PLASMID_TXT = os.path.join(WORKINNG_DIR, r\"cog_words_plasmid.txt\")\n",
    "WORDS_BAC_TXT = os.path.join(WORKINNG_DIR, r\"cog_words_bac.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e037ab76",
   "metadata": {},
   "source": [
    "### 1.1. Find cog problem: Finding the genomes in which the cog appears\n",
    "The function receives a genome and check if the cog appears in it.\n",
    "\n",
    "- Input: genome, HashMap of wordes, cog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b21b6316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take one row from DB and check if cog appears in it\n",
    "def find_cog(data, cog_map, cog):\n",
    "    for row in data:\n",
    "        for i in range(5, len(row)):\n",
    "            if cog == row[i]:\n",
    "                find_words(cog_map, row, i)  # find all neighbors of cog\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c08bbc9",
   "metadata": {},
   "source": [
    "### 1.2. Find Wordes: Finding all of cog's neighbors\n",
    "The function divides the genome into l-length segments and checks if it appears in each segment.\n",
    "If so, it puts the word in the Hashmap\n",
    "\n",
    "- Input: HashMap of words, genome, index of cog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85a8829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all words (cog+neighbors) in a specific row\n",
    "def find_words(cog_map, row, i):\n",
    "    for l_param in range(2, 11):  # number of neighbours 2-10\n",
    "        if l_param <= len(row) - 5:  # 5 is the index of the first cog in the row\n",
    "            for j in range(5, len(row) - l_param + 1):\n",
    "                word = tuple(row[j: j + l_param])  # tuple is hashable (the length of word is l_param)\n",
    "                if row[i] in word:  # if the cog is in the word\n",
    "                    if word in cog_map:  # if the word is already in the hashmap\n",
    "                        value_of_word = cog_map[word]\n",
    "                        value_of_word[0] += 1\n",
    "                        organism = row[3]  # row[3] is the organism's name\n",
    "                        value_of_word[1].add(organism)  # add the organism's name to the set\n",
    "                        cog_map[word] = value_of_word  # set to the map the new value of key 'word'\n",
    "                    else:\n",
    "                        cog_map[word] = [1, {row[3]}]  # add a new key 'word' to the map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dc6e83",
   "metadata": {},
   "source": [
    "### 1.3. bigger_than_q: Find Wordes that are  conserved in â‰¥ ð‘ž of the genomes\n",
    "The function receives a map of all the words and checks if the size of its group of organisms is greater than q.\n",
    "If so, it puts it in a counter with the size\n",
    "\n",
    "- Input: HashMap of words, q, counter that save the wordes and the number genomes in which it appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3142f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the map and only consider words that appear in at least q different organisms\n",
    "def bigger_than_q(cog_map, q, counter):\n",
    "    for key in cog_map:\n",
    "        value = cog_map[key]\n",
    "        if len(value[1]) >= q:  # check if the size of the organisms set is at least q\n",
    "            counter[key] = len(value[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae70ce",
   "metadata": {},
   "source": [
    "### 1.4. sort_output: Sort the words in the counter by length and q\n",
    "The function receives a counter, sorts it into sub-list according to the lengths of the word and sort each list by decreasing number of genomes in which the word was found \n",
    "\n",
    "- Input: counter\n",
    "- output: sort list by length and q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24689bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_output(counter):\n",
    "    output = [] \n",
    "    # Inserting the words into the output by the number of their appearances in the genome, in descending order\n",
    "    for k, v in counter.most_common():\n",
    "        output.append(k)\n",
    "\n",
    "    group = defaultdict(list)\n",
    "    # sort the output by the length\n",
    "    for c in output:\n",
    "        group[len(c)].append(c)\n",
    "    return group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720e380",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eef0e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open, read and split both of the files. return the words that contain the cog and appear in at least q organisms\n",
    "def main(cog, q):\n",
    "    # first file - plasmid\n",
    "    with open(WORDS_PLASMID_TXT, \"rb\") as f:\n",
    "        data1 = f.readlines()  # read content as lines\n",
    "\n",
    "    # split each line by tab (\\t) and remove the new line at the last cell\n",
    "    split1 = [x.split(b\"\\t\")[:-1] for x in data1]\n",
    "\n",
    "    # split the first cell by hashtag (#) and combine with the rest of the list\n",
    "    data1 = [list([*x[0].split(b\"#\"), *x[1:]]) for x in split1]\n",
    "\n",
    "    counter = Counter() # create a Counter with key = word, value = the size of the group that the organism appears in it (q)\n",
    "    cog_map = {}  # create a hashmap with the word (a tuple) as a key and array of [number_of_appears, set_of_organism] as the value\n",
    "    find_cog(data1, cog_map, cog)  # a map of words that contain the cog from the first DB\n",
    "\n",
    "    # open second file - bacteria\n",
    "    with open(WORDS_BAC_TXT, \"rb\") as f:\n",
    "        data2 = f.readlines()  # read content as lines\n",
    "\n",
    "    # split each line by tab (\\t) and remove the new line at the last cell\n",
    "    split2 = [x.split(b\"\\t\")[:-1] for x in data2]\n",
    "\n",
    "    # split the first cell by hashtag (#) and combine with the rest of the list\n",
    "    data2 = [list([*x[0].split(b\"#\"), *x[1:]]) for x in split2]\n",
    "\n",
    "    find_cog(data2, cog_map, cog)  # a map of words that contain the cog from both DB\n",
    "    bigger_than_q(cog_map, q, counter) # update the counter withe wordes that the value bigger than q\n",
    "    \n",
    "    sorted_groups = sort_output(counter) # a  sort list of wordes that appear bigger than q\n",
    "    print(sorted_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e8bfbf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {2: [(b'0279', b'0121'), (b'0121', b'4301'), (b'1262', b'0121'), (b'X', b'0121'), (b'0121', b'X')], 3: [(b'1262', b'0121', b'4301'), (b'3572', b'1262', b'0121'), (b'0121', b'4301', b'0520')], 4: [(b'3572', b'1262', b'0121', b'4301'), (b'1262', b'0121', b'4301', b'0520')], 5: [(b'3572', b'1262', b'0121', b'4301', b'0520')]})\n"
     ]
    }
   ],
   "source": [
    "cog = b\"0121\" \n",
    "main(cog, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
