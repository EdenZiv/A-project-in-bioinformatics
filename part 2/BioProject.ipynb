{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "990a9d49",
   "metadata": {},
   "source": [
    "# A project in bioinformatics\n",
    "\n",
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0cd04e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import timeit\n",
    "\n",
    "import os\n",
    "WORKINNG_DIR = os.getcwd()\n",
    "\n",
    "WORDS_PLASMID_TXT = os.path.join(WORKINNG_DIR, r\"cog_words_plasmid.txt\")\n",
    "WORDS_BAC_TXT = os.path.join(WORKINNG_DIR, r\"cog_words_bac.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e037ab76",
   "metadata": {},
   "source": [
    "### 1.1. Find cog problem: Finding the genomes in which the cog appears\n",
    "The function receives a genome and check if the cog appears in it.\n",
    "\n",
    "- Input: genome, HashMap of wordes, cog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b21b6316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take one row from DB and check if cog appears in it\n",
    "def find_cog(data, cog_map, cog, l):\n",
    "    for row in data:\n",
    "        for i in range(5, len(row)):\n",
    "            if cog == row[i]:\n",
    "                find_words(cog_map, row, i, l)  # find all neighbors of cog\n",
    "                break\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c08bbc9",
   "metadata": {},
   "source": [
    "### 1.2. Find Wordes: Finding all of cog's neighbors\n",
    "The function divides the genome into l-length segments and checks if it appears in each segment.\n",
    "If so, it puts the word in the Hashmap\n",
    "\n",
    "- Input: HashMap of words, genome, index of cog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85a8829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all words (cog+neighbors) in a specific row\n",
    "def find_words(cog_map, row, i, l):\n",
    "    for l_param in range(2, l + 1):  # number of neighbours 2-10\n",
    "        if l_param <= len(row) - 5:  # 5 is the index of the first cog in the row\n",
    "            for j in range(5, len(row) - l_param + 1):\n",
    "                word = tuple(row[j: j + l_param])  # tuple is hashable (the length of word is l_param)\n",
    "                if row[i] in word:  # if the cog is in the word\n",
    "                    if word in cog_map:  # if the word is already in the hashmap\n",
    "                        value_of_word = cog_map[word]\n",
    "                        value_of_word[0] += 1\n",
    "                        organism = row[3]  # row[3] is the organism's name\n",
    "                        value_of_word[1].add(organism)  # add the organism's name to the set\n",
    "                        cog_map[word] = value_of_word  # set to the map the new value of key 'word'\n",
    "                    else:\n",
    "                        cog_map[word] = [1, {row[3]}]  # add a new key 'word' to the map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dc6e83",
   "metadata": {},
   "source": [
    "### 1.3. bigger_than_q: Find Wordes that are  conserved in ≥ 𝑞 of the genomes\n",
    "The function receives a map of all the words and checks if the size of its group of organisms is greater than q.\n",
    "If so, it puts it in a counter with the size\n",
    "\n",
    "- Input: HashMap of words, q, counter that save the wordes and the number genomes in which it appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3142f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the map and only consider words that appear in at least q different organisms\n",
    "def bigger_than_q(cog_map, q, counter):\n",
    "    for key in cog_map:\n",
    "        value = cog_map[key]\n",
    "        if len(value[1]) >= q:  # check if the size of the organisms set is at least q\n",
    "            counter[key] = len(value[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae70ce",
   "metadata": {},
   "source": [
    "### 1.4. sort_output: Sort the words in the counter by length and q\n",
    "The function receives a counter, sorts it into sub-list according to the lengths of the word and sort each list by decreasing number of genomes in which the word was found \n",
    "\n",
    "- Input: counter\n",
    "- output: sort list by length and q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24689bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_output(counter, output):\n",
    "    # Inserting the words into the output by the number of their appearances in the genome, in descending order\n",
    "    for k, v in counter.most_common():\n",
    "        output.append(k)\n",
    "\n",
    "    group = defaultdict(list)\n",
    "    # sort the output by the length\n",
    "    for c in output:\n",
    "        group[len(c)].append(c)\n",
    "    return group\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829a8763",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "### 2.1. k_instances: finding all the wordes with k-instances\n",
    "The function checks for each word result from prat 1 if it appears in this result with k-insrtion. If so, it puts the word in the  new Counter \n",
    "\n",
    "- Input: sorted_groups( the result from part 1), sort list of words, k, counter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5626d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_instances(sorted_groups, output, k, counter2):\n",
    "    for word in output:  \n",
    "        len_word = len(word)\n",
    "        sum_k = 1\n",
    "        check_key = len_word + sum_k\n",
    "        while sum_k <= k and check_key in sorted_groups.keys():  # check if the next group(by key) is in sorted_group\n",
    "            group = sorted_groups.get(check_key)\n",
    "            find_word = is_find_word_k(word, group)  # number of times \"word\" appear in each group\n",
    "            counter2[word] = counter2[word] + find_word  # insert to new Counter\n",
    "            sum_k += 1\n",
    "            check_key += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af2e94f",
   "metadata": {},
   "source": [
    "### 2.2. is_find_word_k: finding the word with k-instances in the group \n",
    "The function receives a word and a group with up to k-instances and goes over each word in the group. If it finds a suitable word it increases the amount of total_sum by 1\n",
    "\n",
    "- Input: word and group of words with tha same length\n",
    "- Output: the number of appreance the word in the group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a6a2044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_find_word_k(word, group):\n",
    "    total_sum = 0\n",
    "    for arr in group:\n",
    "        if word[0] == arr[0] and word[len(word) - 1] == arr[len(arr) - 1]:  # to allow insertions only at the middle\n",
    "            j = 1\n",
    "            for i in range(1, len(arr)):\n",
    "                if word[j] == arr[i]:\n",
    "                    j += 1\n",
    "                if j == len(word):  # means we find all the cogs of word in arr\n",
    "                    total_sum += 1\n",
    "                    break\n",
    "    return total_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bef3ca5",
   "metadata": {},
   "source": [
    "### 2.3 update_counter2: update the values in counter\n",
    "The function receives 2 counters and updates the key values of counter2 to be the sum of its values in counters1 and counter2\n",
    "\n",
    "- Input: sorted_groups (the result from part 1), sort list of words, k, counter2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faf051ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_counter2(counter1, counter2): \n",
    "    for word in counter2:\n",
    "        counter2[word] += counter1[word]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a13c09",
   "metadata": {},
   "source": [
    "### 2.4. bigger_than_q2: Find Wordes that are  conserved in ≥ 𝑞 of the genomes\n",
    "The function receives a counter and checks if the size of its group of organisms is greater than q.\n",
    "If so, it puts it in a new counter with the size\n",
    "\n",
    "- Input: q and counter \n",
    "- Output: counter that contains all the wordes which appear at least q."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d96d0aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigger_than_q2(q, counter):\n",
    "    new_counter = Counter()\n",
    "    for word in counter:\n",
    "        count = counter[word]\n",
    "        if counter[word] >= q:  # check if the size of the organisms set is at least q\n",
    "            new_counter[word] = count\n",
    "    return new_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720e380",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eef0e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open, read and split both of the files. return the words that contain the cog and appear in at least q organisms\n",
    "def main(cog, q, l, k):\n",
    "    # start_time = timeit.default_timer()\n",
    "    # first file - plasmid\n",
    "    with open(WORDS_PLASMID_TXT, \"rb\") as f:\n",
    "        data1 = f.readlines()  # read content as lines\n",
    "\n",
    "    # split each line by tab (\\t) and remove the new line at the last cell\n",
    "    split1 = [x.split(b\"\\t\")[:-1] for x in data1]\n",
    "\n",
    "    # split the first cell by hashtag (#) and combine with the rest of the list\n",
    "    data1 = [list([*x[0].split(b\"#\"), *x[1:]]) for x in split1]\n",
    "\n",
    "    counter1 = Counter()  # create a Counter with key = word, value = the size of the group that the organism appears in it (q)\n",
    "    cog_map = {}  # create a hashmap with the word (a tuple) as a key and array of [number_of_appears, set_of_organism] as the value\n",
    "    find_cog(data1, cog_map, cog, l)  # a map of words that contain the cog from the first DB\n",
    "\n",
    "    # open second file - bacteria\n",
    "    with open(WORDS_BAC_TXT, \"rb\") as f:\n",
    "        data2 = f.readlines()  # read content as lines\n",
    "\n",
    "    # split each line by tab (\\t) and remove the new line at the last cell\n",
    "    split2 = [x.split(b\"\\t\")[:-1] for x in data2]\n",
    "\n",
    "    # split the first cell by hashtag (#) and combine with the rest of the list\n",
    "    data2 = [list([*x[0].split(b\"#\"), *x[1:]]) for x in split2]\n",
    "\n",
    "    find_cog(data2, cog_map, cog, l)  # a map of words that contain the cog from both DB\n",
    "    bigger_than_q(cog_map, 1, counter1)  # update the counter with the words that the value bigger than q\n",
    "    output = []\n",
    "    sorted_groups = sort_output(counter1, output)  # a  sort list of words that appear at least one\n",
    "    \n",
    "    if k == 0:  # no insertions\n",
    "        new_counter = bigger_than_q2(q, counter1)\n",
    "        output = []\n",
    "        sorted_groups_k = sort_output(new_counter, output)\n",
    "        print(sorted_groups_k)\n",
    "    else:\n",
    "        counter2 = Counter()\n",
    "        k_instances(sorted_groups, output, k, counter2)\n",
    "        update_counter2(counter1, counter2)\n",
    "        new_counter = bigger_than_q2(q, counter2)\n",
    "        output = []  # to clear the output\n",
    "        sorted_groups_k = sort_output(new_counter, output)\n",
    "        print(sorted_groups_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8bfbf0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {2: [(b'X', b'0586'), (b'0586', b'X'), (b'0101', b'0586'), (b'0586', b'0777'), (b'0626', b'0586'), (b'2186', b'0586'), (b'2207', b'0586'), (b'0586', b'0586'), (b'0586', b'0260'), (b'3963', b'0586'), (b'0586', b'0322'), (b'0503', b'0586'), (b'0586', b'1322'), (b'0586', b'0861'), (b'3339', b'0586'), (b'1051', b'0586'), (b'0586', b'2244'), (b'0499', b'0586')], 3: [(b'0136', b'0101', b'0586'), (b'0101', b'0586', b'0777'), (b'0586', b'0777', b'0285'), (b'0586', b'X', b'X'), (b'X', b'X', b'0586'), (b'2271', b'2186', b'0586'), (b'X', b'0586', b'X'), (b'2186', b'0586', b'X'), (b'0586', b'0260', b'0012'), (b'2186', b'0586', b'0322'), (b'0503', b'0586', b'0260'), (b'X', b'0503', b'0586'), (b'0586', b'1322', b'2226'), (b'5337', b'1051', b'0586'), (b'1051', b'0586', b'2244'), (b'0586', b'2244', b'0598')], 4: [(b'0136', b'0101', b'0586', b'0777'), (b'0101', b'0586', b'0777', b'0285'), (b'0111', b'0136', b'0101', b'0586'), (b'0586', b'0777', b'0285', b'3147'), (b'0586', b'X', b'X', b'4575'), (b'0503', b'0586', b'0260', b'0012'), (b'2271', b'2186', b'0586', b'X'), (b'0698', b'X', b'0503', b'0586'), (b'X', b'0503', b'0586', b'0260'), (b'0586', b'1322', b'2226', b'3165'), (b'5337', b'1051', b'0586', b'2244'), (b'1051', b'0586', b'2244', b'0598')]})\n"
     ]
    }
   ],
   "source": [
    " main(b\"0586\", 20,5 ,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
